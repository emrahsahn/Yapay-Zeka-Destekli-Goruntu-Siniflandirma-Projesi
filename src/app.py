"""
Gradio Web Application for Animal Image Classifier

This module provides a user-friendly web interface for the animal classifier.
Users can upload animal images and receive instant predictions with confidence scores.

Features:
- Image upload via drag-and-drop or file browser
- Real-time inference using trained model
- Top-3 predictions with confidence percentages
- Clean, modern UI using Gradio Soft theme
- Automatic translation from Italian to Turkish class names

Usage:
    python src/app.py

The application will launch at http://127.0.0.1:7860

Performance:
- Inference time: ~50ms per image on CPU, ~5ms on GPU
- Supports images of any size (automatically resized to 224x224)
- Memory usage: ~200MB (model loaded in memory)

Supported Animals (10 classes):
    üêï K√∂pek (Dog)       üê¥ At (Horse)        üêò Fil (Elephant)
    ü¶ã Kelebek (Butterfly) üêî Tavuk (Chicken)   üê± Kedi (Cat)
    üêÑ ƒ∞nek (Cow)        üêë Koyun (Sheep)     üï∑Ô∏è √ñr√ºmcek (Spider)
    üêøÔ∏è Sincap (Squirrel)
"""

SRC_DIR = 'src\\'

import gradio as gr
import tensorflow as tf
import numpy as np
from preprocessing import preprocess_image
from data_loader import get_class_names

# Model Configuration
# -------------------
# Path to the trained model file (saved in Keras format)
# This model should be generated by running: python src/train_model.py
MODEL_PATH = 'model_artifacts/animal_classifier.keras'

# Load Trained Model
# ------------------
# Time: O(model_size) for loading from disk, typically 1-2 seconds
# The model is loaded once at startup and kept in memory for fast inference
print("Loading model...")
try:
    # Load complete model including:
    # - Architecture (layers and connections)
    # - Trained weights (3.5M parameters)
    # - Optimizer state (for continued training, not used here)
    # Space: ~14MB model + ~200MB runtime memory
    model = tf.keras.models.load_model(MODEL_PATH)
    print("‚úì Model loaded successfully.")
    print(f"  Model input shape: {model.input_shape}")
    print(f"  Model output shape: {model.output_shape}")
    print(f"  Total parameters: {model.count_params():,}")
except Exception as e:
    # Graceful degradation if model not found
    # Allows development/testing without trained model
    print(f"‚ö† Warning: Could not load model from {MODEL_PATH}")
    print(f"  Error: {e}")
    print(f"  Predictions will return dummy data.")
    print(f"  To train the model, run: python src/train_model.py")
    model = None

# Load Class Names and Translation Map
# ------------------------------------
# Time: O(c) where c = number of classes (10)
try:
    # Get Italian class names from dataset directory structure
    class_names = get_class_names()
    
    # Translation Map: Italian -> Turkish
    # -----------------------------------
    # Animals-10 dataset uses Italian labels (original dataset source)
    # We translate to Turkish for Turkish-speaking users
    # This mapping is static and matches the alphabetically sorted class names
    # Time: O(1) dictionary lookups
    translation_map = {
        'cane': 'K√∂pek',        # Dog
        'cavallo': 'At',        # Horse
        'elefante': 'Fil',      # Elephant
        'farfalla': 'Kelebek',  # Butterfly
        'gallina': 'Tavuk',     # Chicken
        'gatto': 'Kedi',        # Cat
        'mucca': 'ƒ∞nek',        # Cow
        'pecora': 'Koyun',      # Sheep
        'ragno': '√ñr√ºmcek',     # Spider
        'scoiattolo': 'Sincap'  # Squirrel
    }
    
    # Create Turkish class names list maintaining order
    # Time: O(c) where c = 10 classes
    # .get(c, c) returns c if not found in map (fallback to original)
    class_names_tr = [translation_map.get(c, c) for c in class_names]
    print(f"‚úì Loaded {len(class_names)} class names")
    
except Exception as e:
    print(f"‚ö† Warning: Could not load class names. Error: {e}")
    class_names = []
    class_names_tr = []


def predict(image):
    """
    Performs inference on uploaded image and returns class predictions.
    
    This function:
    1. Validates input image
    2. Preprocesses image (resize, normalize)
    3. Runs model inference
    4. Converts outputs to probability scores
    5. Formats results for Gradio display
    
    Args:
        image: numpy.ndarray or None
               Image data from Gradio interface
               Shape: (H, W, 3) with values in range [0, 255]
               H, W can be any size (will be resized to 224x224)
    
    Returns:
        dict: Class names (Turkish) mapped to confidence scores
              Format: {"K√∂pek": 0.85, "Kedi": 0.10, ...}
              Returns None if image is None
              Returns error dict if model not loaded
    
    Time Complexity:
        O(preprocessing) + O(inference) + O(postprocessing)
        - Preprocessing: O(H*W) for resize + O(150K) for normalize
        - Inference: O(3.5M) for forward pass through model
        - Postprocessing: O(10) for formatting results
        Total: ~50ms on CPU, ~5ms on GPU
    
    Space Complexity:
        O(224*224*3) for preprocessed image
        + O(model_activations) during inference
        Peak: ~200MB during inference
    
    Example:
        >>> img = np.random.randint(0, 255, (500, 500, 3), dtype=np.uint8)
        >>> result = predict(img)
        >>> print(result)
        {"K√∂pek": 0.85, "Kedi": 0.10, "At": 0.03, ...}
    """
    # Error Handling: Model Not Loaded
    # --------------------------------
    if model is None:
        return {"‚ö† Hata: Model y√ºklenmedi": 1.0}
    
    # Input Validation
    # ----------------
    if image is None:
        return None

    # Image Preprocessing Pipeline
    # ----------------------------
    # Gradio provides image as numpy array with shape (H, W, 3)
    # Values are in range [0, 255] (uint8 or int32)
    # We need to apply same preprocessing as during training:
    # 1. Resize to 224x224
    # 2. Normalize to [0, 1]
    # Time: O(H*W) for resize + O(150K) for normalization
    img_processed = preprocess_image(image)
    
    # Add Batch Dimension
    # -------------------
    # Model expects input shape: (batch_size, 224, 224, 3)
    # Our single image has shape: (224, 224, 3)
    # expand_dims adds dimension: (1, 224, 224, 3)
    # Time: O(1) - just reshapes tensor, no data copy
    img_expanded = tf.expand_dims(img_processed, 0)

    # Model Inference
    # ---------------
    # Forward pass through neural network
    # Input: (1, 224, 224, 3) tensor with values in [0, 1]
    # Output: (1, 10) tensor with probability distribution
    # Time: O(3.5M) multiply-add operations
    # - CPU: ~50ms per image
    # - GPU: ~5ms per image
    # verbose=0 suppresses progress output for cleaner UI
    predictions = model.predict(img_expanded, verbose=0)
    
    # Extract Probability Scores
    # --------------------------
    # predictions shape: (1, 10) - batch of 1, 10 class probabilities
    # predictions[0] extracts first (and only) sample: (10,)
    # Model already has softmax activation, so values are probabilities [0, 1]
    # Sum of all probabilities = 1.0
    # Time: O(1) - array indexing
    scores = predictions[0]

    # Format Results for Gradio
    # -------------------------
    # Gradio Label component expects dict format:
    # {"Label1": confidence1, "Label2": confidence2, ...}
    # It automatically sorts by confidence and shows top 3
    # Time: O(c) where c = 10 classes
    result = {}
    for i, score in enumerate(scores):
        # Get Turkish label name, fallback to "Class {i}" if not available
        label = class_names_tr[i] if i < len(class_names_tr) else f"Class {i}"
        
        # Convert numpy float to Python float for JSON serialization
        result[label] = float(score)
    
    return result

# Gradio Web Interface
# =====================
# Gradio provides a fast way to create web UIs for ML models
# - No HTML/CSS/JavaScript needed
# - Automatic API generation
# - Built-in example gallery and sharing features

# UI Theme Configuration
# ----------------------
# gr.themes.Soft() provides a clean, modern look with:
# - Rounded corners
# - Soft shadows
# - Pastel color palette
# - High contrast for accessibility
with gr.Blocks(theme=gr.themes.Soft(), title="Yapay Zeka Destekli G√∂r√ºnt√º Sƒ±nƒ±flandƒ±rƒ±cƒ±") as demo:
    
    # Header Section
    # --------------
    # Markdown component for formatted text
    # Supports emojis, bold, italic, lists, etc.
    gr.Markdown(
        """
        # ü¶Å Yapay Zeka Destekli G√∂r√ºnt√º Sƒ±nƒ±flandƒ±rƒ±cƒ±
        
        Bu uygulama, y√ºklediƒüiniz hayvan fotoƒüraflarƒ±nƒ± yapay zeka ile analiz eder 
        ve hangi hayvana ait olduƒüunu y√ºksek doƒürulukla tahmin eder.
        
        **Tanƒ±mlanabilen Hayvanlar (10 Sƒ±nƒ±f):**  
        üêï K√∂pek ‚Ä¢ üê¥ At ‚Ä¢ üêò Fil ‚Ä¢ ü¶ã Kelebek ‚Ä¢ üêî Tavuk  
        üê± Kedi ‚Ä¢ üêÑ ƒ∞nek ‚Ä¢ üêë Koyun ‚Ä¢ üï∑Ô∏è √ñr√ºmcek ‚Ä¢ üêøÔ∏è Sincap
        
        ---
        **Kullanƒ±m:** Bir hayvan fotoƒürafƒ± y√ºkleyin ve "Analiz Et" butonuna tƒ±klayƒ±n.
        """
    )
    
    # Main Layout: Two Columns
    # ------------------------
    # Left column: Input (image upload + button)
    # Right column: Output (prediction results)
    with gr.Row():
        # Input Column
        # ------------
        with gr.Column():
            # Image Upload Component
            # type="numpy": Returns image as numpy array for easy processing
            # Supports: drag-and-drop, file browser, webcam (optional)
            # Accepted formats: JPG, PNG, GIF, BMP, WEBP
            input_image = gr.Image(
                label="üì§ G√∂r√ºnt√º Y√ºkle", 
                type="numpy",
                height=400
            )
            
            # Predict Button
            # variant="primary": Makes button stand out with accent color
            predict_btn = gr.Button("üîç Analiz Et", variant="primary", size="lg")
        
        # Output Column
        # -------------
        with gr.Column():
            # Label Component for Classification Results
            # num_top_classes=3: Shows top 3 predictions with confidence bars
            # Automatically sorted by confidence (highest first)
            # Visual confidence bars for easy interpretation
            output_label = gr.Label(
                label="üìä Tahmin Sonucu", 
                num_top_classes=3
            )
    
    # Example Images Section (Optional)
    # ---------------------------------
    # Uncomment to add example images for quick testing
    # Users can click examples instead of uploading their own images
    # gr.Examples(
    #     examples=[
    #         'data/raw-img/cane/dog1.jpg',
    #         'data/raw-img/gatto/cat1.jpg',
    #         'data/raw-img/elefante/elephant1.jpg',
    #     ],
    #     inputs=input_image,
    #     label="üì∏ √ñrnek G√∂rseller"
    # )

    # Event Binding: Button Click
    # ---------------------------
    # When predict_btn is clicked:
    # 1. Gets value from input_image
    # 2. Calls predict() function
    # 3. Updates output_label with results
    # Time: ~50ms for inference + <10ms for UI update
    predict_btn.click(
        fn=predict,              # Function to call
        inputs=input_image,      # Input component
        outputs=output_label     # Output component to update
    )

# Application Launch Configuration
# =================================
if __name__ == "__main__":
    # Launch Gradio app with custom settings
    # server_name="127.0.0.1": Only accessible from localhost (secure default)
    # - Change to "0.0.0.0" to allow external access (use with caution)
    # server_port=7860: Standard Gradio port
    # - Browser will open automatically at http://127.0.0.1:7860
    # 
    # Additional useful parameters:
    # - share=True: Creates public URL for sharing (via Gradio tunneling)
    # - auth=("username", "password"): Adds password protection
    # - favicon_path="icon.png": Custom favicon
    # 
    # The app will run until interrupted (Ctrl+C)
    print("\n" + "="*60)
    print("üöÄ Launching Gradio Application...")
    print("="*60)
    print("üìç Local URL: http://127.0.0.1:7860")
    print("‚èπÔ∏è  Press Ctrl+C to stop the server")
    print("="*60 + "\n")
    
    demo.launch(
        server_name="127.0.0.1",  # Localhost only (secure)
        server_port=7860,          # Standard port
        show_error=True            # Show detailed errors in UI (helpful for debugging)
    )
